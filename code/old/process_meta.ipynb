{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import logging\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_folder = os.path.join(get_data_folder(), 'meta')\n",
    "processed_folder = get_processed_folder()\n",
    "route_names = load_route_names()\n",
    "routes = {rname:load_ordered_route_vdss_from_excel(rname) for rname in route_names}\n",
    "logging.basicConfig(filename='process_meta.log',\n",
    "                    encoding='utf-8',\n",
    "                    level=logging.INFO,\n",
    "                    filemode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# All VDSs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "route_vdss = set()\n",
    "for route in routes.values():\n",
    "    if route is not None:\n",
    "        route_vdss.update( route )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "route_vdss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather list of metadata files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = list()\n",
    "for filename in os.listdir(meta_folder):\n",
    "\n",
    "    file_split = os.path.splitext(filename)\n",
    "\n",
    "    if file_split[1]!='.txt':\n",
    "        continue\n",
    "\n",
    "    a = file_split[0].split(\"_\")\n",
    "    district = int(a[0][1:])\n",
    "    year = int(a[3])\n",
    "    month = int(a[4])\n",
    "    day = int(a[5])\n",
    "\n",
    "    rows.append([district,  year, month, day, filename])\n",
    "\n",
    "files_table = pd.DataFrame(rows,columns=['district', 'year', 'month', 'day','filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Creatae dictionary of district -> VDS ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "district2vdss = dict()\n",
    "\n",
    "for index, row in files_table.iterrows():\n",
    "\n",
    "    df = pd.read_csv(os.path.join(meta_folder, row['filename']),sep='\\t',dtype={'ID':str})\n",
    "    district = df.loc[0,'District']\n",
    "\n",
    "    if district not in district2vdss.keys():\n",
    "        district2vdss[district] = set()\n",
    "\n",
    "    dfvds = set(df['ID'].values)\n",
    "    dfvds = dfvds.intersection(route_vdss)\n",
    "\n",
    "    district2vdss[district] = district2vdss[district].union(dfvds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "district2vdss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gather meta data history for each VDS\n",
    "# Save as processed/meta_district_vds_hist_{district}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_vds(logging, vds_table, vds):\n",
    "\n",
    "    if len(np.unique(vds_table['Fwy']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple freeways.')\n",
    "\n",
    "    if len(np.unique(vds_table['Dir']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple directions.')\n",
    "\n",
    "    if len(np.unique(vds_table['District']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple districts.')\n",
    "\n",
    "    if len(np.unique(vds_table['County']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple counties.')\n",
    "\n",
    "    if len(np.unique(vds_table['State_PM']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple state PMs.')\n",
    "\n",
    "    if len(np.unique(vds_table['Abs_PM']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple absolute PMs.')\n",
    "\n",
    "    if len(np.unique(vds_table['Latitude']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple latitude.')\n",
    "\n",
    "    if len(np.unique(vds_table['Longitude']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple longitude.')\n",
    "\n",
    "    if len(np.unique(vds_table['Type']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple type.')\n",
    "\n",
    "    if len(np.unique(vds_table['Lanes']))>1:\n",
    "        logging.warning(f'VDS {vds} has multiple lanes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for district, vdss in district2vdss.items():\n",
    "\n",
    "    print(district)\n",
    "\n",
    "    if len(vdss)==0:\n",
    "        continue\n",
    "\n",
    "    vds_tables = dict.fromkeys(vdss)\n",
    "    district_files = files_table[files_table['district']==district]\n",
    "\n",
    "    for ind, file_row in district_files.iterrows():\n",
    "\n",
    "        year = file_row[1]\n",
    "        month = file_row[2]\n",
    "        day = file_row[3]\n",
    "        filename = file_row[4]\n",
    "\n",
    "        df = pd.read_csv(os.path.join(meta_folder, filename),dtype={'ID':str},sep='\\t')\n",
    "\n",
    "        for vds in district2vdss[district]:\n",
    "            dfvds = df.loc[df['ID']==vds,:]\n",
    "            vds_table = vds_tables[vds]\n",
    "\n",
    "            if vds_table is None:\n",
    "                vds_table = dfvds.copy()\n",
    "                vds_table.insert(0,'date',pd.Timestamp(year=year,month=month,day=day))\n",
    "            else:\n",
    "                new_row = dfvds.copy()\n",
    "                new_row.insert(0,'date',pd.Timestamp(year=year,month=month,day=day))\n",
    "                vds_table = pd.concat((vds_table,new_row))\n",
    "\n",
    "            vds_tables[vds] = vds_table\n",
    "\n",
    "    # keep differences\n",
    "    df = pd.DataFrame()\n",
    "    for vds, vds_table in vds_tables.items():\n",
    "\n",
    "        # correct State_PM that contain characters\n",
    "        try:\n",
    "            state_pm_str = [str(x) for x in vds_table['State_PM']]\n",
    "            vds_table['State_PM'] = [float(''.join(x for x in str if not x.isalpha())) for str in state_pm_str]\n",
    "        except:\n",
    "            logging.warning(f\"Cannot cast state PM for vds {vds} to float: {vds_table['State_PM']}\")\n",
    "\n",
    "        vds_table.sort_values('date', inplace=True)\n",
    "        cols = np.setdiff1d(vds_table.columns.values, ('date', 'User_ID_1', 'User_ID_2', 'User_ID_3', 'User_ID_4'))\n",
    "        np.setdiff1d(vds_table.columns.values, {'date', 'User_ID_1'})\n",
    "        both_nan = vds_table[cols].shift().isna() & vds_table[cols].isna()\n",
    "        equal_val = vds_table[cols].shift() == vds_table[cols]\n",
    "\n",
    "        vds_table = vds_table.loc[~(both_nan | equal_val).all(axis=1)]\n",
    "\n",
    "        check_vds(logging, vds_table, vds)\n",
    "\n",
    "        if len(df) == 0:\n",
    "            df = vds_table\n",
    "        else:\n",
    "            df = pd.concat((df, vds_table))\n",
    "\n",
    "    df.to_csv(os.path.join(processed_folder, f'meta_district_vds_hist_{district}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tables for routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for route_name, vdss in routes.items():\n",
    "    print(route_name)\n",
    "\n",
    "    if vdss==None:\n",
    "        continue\n",
    "\n",
    "    districts = get_districts_for_vdss(vdss)\n",
    "    vds_table = load_districts_config(districts)\n",
    "\n",
    "    route_table = pd.DataFrame()\n",
    "    for vds in vdss:\n",
    "        route_table = pd.concat((route_table, vds_table[vds_table['ID']==vds]))\n",
    "\n",
    "    route_table.to_csv(os.path.join(processed_folder, f'meta_route_vds_hist_{route_name}.csv'))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
