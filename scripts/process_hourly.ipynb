{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "WARNING: Remember to remove hourly files from the processed folder before running this script. This script is cumulative in the sense that it appends to existing processed files, so if you do not remove the files, they will contain redundant information which may cause downstream methods to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dirname = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "meta_folder = os.path.join(dirname, '../data/meta')\n",
    "hourly_folder = os.path.join(dirname, '../data/hourly')\n",
    "processed_folder = get_processed_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "routes, _ = load_routes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Choose a district, load meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(processed_folder, 'meta_vds_dict.txt')) as f:\n",
    "    vds_dict = ast.literal_eval( f.read() )\n",
    "\n",
    "my_district = 8 # int(input('Choose a district: {}'.format(vds_dict.keys())))\n",
    "\n",
    "vds_table, all_vdss = load_vds_table(my_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Collect table of files available for the given district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = list()\n",
    "for filename in os.listdir(hourly_folder):\n",
    "\n",
    "    file_split = os.path.splitext(filename)\n",
    "\n",
    "    if file_split[1]!='.txt':\n",
    "        continue\n",
    "\n",
    "    a = file_split[0].split(\"_\")\n",
    "    district = int(a[0][1:])\n",
    "    year = int(a[4])\n",
    "    month = int(a[5])\n",
    "\n",
    "    if district!=my_district:\n",
    "        continue\n",
    "\n",
    "    rows.append([district,  year, month, filename])\n",
    "\n",
    "files_table = pd.DataFrame(rows,columns=['district', 'year', 'month','filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gomes/code/hovdeg/scripts/../data/hourly/d07_text_station_hour_2019_04.txt\n",
      "/home/gomes/code/hovdeg/scripts/../data/hourly/d07_text_station_hour_2019_03.txt\n",
      "/home/gomes/code/hovdeg/scripts/../data/hourly/d07_text_station_hour_2019_06.txt\n",
      "/home/gomes/code/hovdeg/scripts/../data/hourly/d07_text_station_hour_2019_07.txt\n"
     ]
    }
   ],
   "source": [
    "# Process each file\n",
    "# Save to {vds}_hourly.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "\n",
    "    cols = ['timestamp', 'station', 'district', 'route', 'dir', 'lanetype', 'stn_length', 'samples', 'perc_obs',\n",
    "            'total_flow', 'avg_occ', 'avg_speed', 'delay_35', 'delay_40', 'delay_45', 'delay_50', 'delay_55', 'delay_60']\n",
    "\n",
    "    for index, row in files_table.iterrows():\n",
    "\n",
    "        text_file = os.path.join(hourly_folder, row['filename'])\n",
    "\n",
    "        print(text_file)\n",
    "\n",
    "        df = pd.read_csv(text_file, header=None)\n",
    "\n",
    "        nrows, ncols = df.shape\n",
    "\n",
    "        # figure out the header for the file\n",
    "        nlanes = int((ncols-len(cols))/3)\n",
    "        colnames = cols.copy()\n",
    "        flw_cols = []\n",
    "        occ_cols = []\n",
    "        spd_cols = []\n",
    "        for lane in range(nlanes):\n",
    "            colnames.append(f'lane_flw_{lane+1}')\n",
    "            colnames.append(f'lane_avg_occ_{lane+1}')\n",
    "            colnames.append(f'lane_avg_spd_{lane+1}')\n",
    "\n",
    "            flw_cols.append(f'lane_flw_{lane+1}')\n",
    "            occ_cols.append(f'lane_avg_occ_{lane+1}')\n",
    "            spd_cols.append(f'lane_avg_spd_{lane+1}')\n",
    "\n",
    "        df.columns = colnames\n",
    "\n",
    "        # filter all_vdss\n",
    "        ind = [vds in all_vdss for vds in df['station']]\n",
    "        df = df[ind]\n",
    "\n",
    "        # Drop lane information\n",
    "        df = df.drop(columns = flw_cols)\n",
    "        df = df.drop(columns = occ_cols)\n",
    "        df = df.drop(columns = spd_cols)\n",
    "\n",
    "        # Drop other information\n",
    "        df = df.drop(columns=['district','delay_35', 'delay_40', 'delay_45', 'delay_50', 'delay_55', 'delay_60'])\n",
    "\n",
    "        # store in files per vds\n",
    "        for vds in all_vdss:\n",
    "\n",
    "            df_vds = df[df['station']==vds].copy()\n",
    "            df_vds = df_vds.set_index('timestamp')\n",
    "\n",
    "            filename = os.path.join(processed_folder,f'{vds}_hourly.csv')\n",
    "            if exists(filename):\n",
    "                a = pd.read_csv(filename)\n",
    "                a = a.set_index('timestamp')\n",
    "                df_vds = pd.concat((a,df_vds),ignore_index=False)\n",
    "\n",
    "            df_vds = df_vds.sort_index()\n",
    "            df_vds.to_csv(filename)\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(processed_folder,'400045_hourly.csv')\n",
    "df_vds = pd.read_csv(filename,index_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_vds['total_flow'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_vds['avg_occ'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_vds['avg_speed'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Daily station health\n",
    "# Save to vds_health_{cfg_name}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for route_name, route_vdss in routes.items():\n",
    "\n",
    "    print(route_name)\n",
    "\n",
    "    # Collect all days from hourly files for these vdss\n",
    "    days_set = set()\n",
    "    for vds in route_vdss:\n",
    "\n",
    "        filename = os.path.join(processed_folder,f'{vds}_hourly.csv')\n",
    "        df_vds = pd.read_csv(filename,index_col='timestamp')\n",
    "        days = set(pd.Timestamp(t).date() for t in df_vds.index)\n",
    "        days_set.update(days)\n",
    "\n",
    "    route_days = pd.Series(list(days_set))\n",
    "    route_days = route_days.sort_values()\n",
    "\n",
    "    # vds_health\n",
    "    vds_health = pd.DataFrame(index=route_days, columns=route_vdss)\n",
    "\n",
    "    for vds in route_vdss:\n",
    "\n",
    "        filename = os.path.join(processed_folder,f'{vds}_hourly.csv')\n",
    "        df_vds = pd.read_csv(filename)\n",
    "        df_vds['date'] = [pd.Timestamp(t).date() for t in df_vds['timestamp']]\n",
    "\n",
    "        for day in route_days:\n",
    "            ind = df_vds['date']==day\n",
    "            vds_health.loc[day,vds] = df_vds.loc[ind,'perc_obs'].mean(skipna=True)\n",
    "\n",
    "    # Save to file\n",
    "    filename = os.path.join(processed_folder,f'vds_health_{route_name}.csv')\n",
    "    vds_health.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
