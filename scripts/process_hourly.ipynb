{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "WARNING: Remember to remove hourly files from the processed folder before running this script. This script is cumulative in the sense that it appends to existing processed files, so if you do not remove the files, they will contain redundant information which may cause downstream methods to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import logging\n",
    "\n",
    "dirname = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "meta_folder = os.path.join(dirname, '../data/meta')\n",
    "hourly_folder = os.path.join(dirname, '../data/hourly')\n",
    "processed_folder = get_processed_folder()\n",
    "logging.basicConfig(filename='process_hourly.log',\n",
    "                    encoding='utf-8',\n",
    "                    level=logging.INFO,\n",
    "                    filemode='w')\n",
    "\n",
    "def load_filestable(my_district):\n",
    "\n",
    "    rows = list()\n",
    "    for filename in os.listdir(hourly_folder):\n",
    "\n",
    "        file_split = os.path.splitext(filename)\n",
    "\n",
    "        if file_split[1]!='.txt':\n",
    "            continue\n",
    "\n",
    "        a = file_split[0].split(\"_\")\n",
    "        district = int(a[0][1:])\n",
    "        year = int(a[4])\n",
    "        month = int(a[5])\n",
    "\n",
    "        if district!=my_district:\n",
    "            continue\n",
    "\n",
    "        rows.append([district,  year, month, filename])\n",
    "\n",
    "    files_table = pd.DataFrame(rows,columns=['district', 'year', 'month','filename'])\n",
    "    return files_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_districts = [7, 3, 8, 12]\n",
    "cols = ['timestamp', 'station', 'district', 'route', 'dir', 'lanetype', 'stn_length', 'samples', 'perc_obs',\n",
    "        'total_flow', 'avg_occ', 'avg_speed', 'delay_35', 'delay_40', 'delay_45', 'delay_50', 'delay_55', 'delay_60']\n",
    "\n",
    "for my_district in all_districts:\n",
    "\n",
    "    vds_table = load_vds_table(my_district)\n",
    "    all_vdss = set(vds_table['ID'].values)\n",
    "\n",
    "    files_table = load_filestable(my_district)\n",
    "\n",
    "    for index, row in files_table.iterrows():\n",
    "\n",
    "        text_file = os.path.join(hourly_folder, row['filename'])\n",
    "\n",
    "        print(text_file)\n",
    "\n",
    "        df = pd.read_csv(text_file, header=None)\n",
    "\n",
    "        nrows, ncols = df.shape\n",
    "\n",
    "        # figure out the header for the file\n",
    "        nlanes = int((ncols-len(cols))/3)\n",
    "        colnames = cols.copy()\n",
    "        flw_cols = []\n",
    "        occ_cols = []\n",
    "        spd_cols = []\n",
    "        for lane in range(nlanes):\n",
    "            colnames.append(f'lane_flw_{lane+1}')\n",
    "            colnames.append(f'lane_avg_occ_{lane+1}')\n",
    "            colnames.append(f'lane_avg_spd_{lane+1}')\n",
    "\n",
    "            flw_cols.append(f'lane_flw_{lane+1}')\n",
    "            occ_cols.append(f'lane_avg_occ_{lane+1}')\n",
    "            spd_cols.append(f'lane_avg_spd_{lane+1}')\n",
    "\n",
    "        df.columns = colnames\n",
    "\n",
    "        # filter all_vdss\n",
    "        ind = [vds in all_vdss for vds in df['station']]\n",
    "        df = df[ind]\n",
    "\n",
    "        # Drop lane information\n",
    "        df = df.drop(columns = flw_cols)\n",
    "        df = df.drop(columns = occ_cols)\n",
    "        df = df.drop(columns = spd_cols)\n",
    "\n",
    "        # Drop other information\n",
    "        df = df.drop(columns=['district','delay_35', 'delay_40', 'delay_45', 'delay_50', 'delay_55', 'delay_60'])\n",
    "\n",
    "        # store in files per vds\n",
    "        for vds in all_vdss:\n",
    "\n",
    "            if not (df['station']==vds).any():\n",
    "                logging.warning(f\"{vds} not found in {text_file}\")\n",
    "\n",
    "            df_vds = df[df['station']==vds].copy()\n",
    "            df_vds = df_vds.set_index('timestamp')\n",
    "\n",
    "            filename = os.path.join(processed_folder,f'{vds}_hourly.csv')\n",
    "            if exists(filename):\n",
    "                a = pd.read_csv(filename)\n",
    "                a = a.set_index('timestamp')\n",
    "                df_vds = pd.concat((a,df_vds),ignore_index=False)\n",
    "\n",
    "            df_vds = df_vds.sort_index()\n",
    "            df_vds.to_csv(filename)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
